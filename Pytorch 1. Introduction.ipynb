{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3803c221",
   "metadata": {},
   "source": [
    "<div style=\"display:block\" direction=rtl align=right><br><br>\n",
    "    <div  style=\"width:100%;margin:100;display:block\"  display=block align=center>\n",
    "        <img width=130 align=right src=\"https://i.ibb.co/yXKQmtZ/logo1.png\" style=\"margin:0;\" />\n",
    "        <img width=170 align=left  src=\"https://i.ibb.co/wLjqFkw/logo2.png\" style=\"margin:0;\" />\n",
    "        <span><br><font size=5>University of Tehran , school of ECE</font></span>\n",
    "        <span><br><font size=3>Deep Learning</font></span>\n",
    "        <span><br><font size=3>Spring 2023</font></span>\n",
    "    </div><br><br><br>\n",
    "    <div style=\"display:block\" align=left display=block> \n",
    "        <font size=3>Pytorch tutorial - Introduction</font><br>\n",
    "        <hr />\n",
    "        <font size=3>TA: <a href=\"mailto:farshads7778@gmail.com\">Farshad Sangari</a></font><br>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c1281dd",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e053102",
   "metadata": {},
   "source": [
    "#### Pytorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ceab0082",
   "metadata": {},
   "source": [
    "| Feature | Description |\n",
    "| --- | --- |\n",
    "| Dynamic computational graph | PyTorch uses a dynamic computational graph that allows for more flexible model building and experimentation. This means that the graph is built on-the-fly during execution, which is particularly useful when building complex, custom models. |\n",
    "| Easy to use | PyTorch has a simple and intuitive API, which makes it easy to use for researchers and developers. Additionally, it has good documentation and a large community that provides support and resources. |\n",
    "| GPU acceleration | PyTorch supports GPU acceleration, which allows for faster training of deep learning models on large datasets. |\n",
    "| TorchScript | PyTorch's TorchScript allows for easy deployment of models in production environments. It enables models to be compiled to a highly optimized form, improving inference speed and efficiency. |\n",
    "| Active development | PyTorch is under active development and has a strong community that is constantly contributing to its development, adding new features and improving its performance. |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "842c87a9",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d7a7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1463b64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "205e55e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99bdb217",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Create tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75c99edc",
   "metadata": {},
   "source": [
    "### From list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c54f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(lst,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50494ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [1,2,3,4]\n",
    "tensor = torch.tensor(lst)\n",
    "tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f96c8ee3",
   "metadata": {},
   "source": [
    "### From an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "141b3ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.5, 1. , 1.5, 2. ],\n",
       "       [2.5, 3. , 3.5, 4. , 4.5],\n",
       "       [5. , 5.5, 6. , 6.5, 7. ],\n",
       "       [7.5, 8. , 8.5, 9. , 9.5]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(0,10,0.5).reshape((4,5))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8dfdf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.5000, 1.0000, 1.5000, 2.0000],\n",
       "        [2.5000, 3.0000, 3.5000, 4.0000, 4.5000],\n",
       "        [5.0000, 5.5000, 6.0000, 6.5000, 7.0000],\n",
       "        [7.5000, 8.0000, 8.5000, 9.0000, 9.5000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(arr)\n",
    "# torch.tensor(arr)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4e5c31",
   "metadata": {},
   "source": [
    "## Convert tensor to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9f4b754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7465, -0.7677,  0.3285],\n",
       "        [ 0.9505, -2.0108,  0.8239]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.randn(size=(2,3))\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261e0d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8154926 ,  0.2954548 ,  0.27072006],\n",
       "       [-0.43916583, -0.5230534 , -0.5413519 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensor1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d5c561",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Some special forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96bb5e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_shape = (3,4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b104567",
   "metadata": {},
   "source": [
    "### Ones tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceed5068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(tensor_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54db2caa",
   "metadata": {},
   "source": [
    "### Zeros tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23bcb64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(tensor_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fd5b9d4",
   "metadata": {},
   "source": [
    "### Diagonal tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7277fe8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 1, 7, 9])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randint(10,(4,))\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fa1f780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 0, 7, 0],\n",
       "        [0, 0, 0, 9]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b741560f",
   "metadata": {},
   "source": [
    "## Random tensors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41534de7",
   "metadata": {},
   "source": [
    "### Uniformly from the interval [0, 1) tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb187962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6110, 0.1217, 0.0567, 0.4756],\n",
       "        [0.6581, 0.0156, 0.2570, 0.3913],\n",
       "        [0.7994, 0.4307, 0.6324, 0.9574]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(tensor_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b552c9e0",
   "metadata": {},
   "source": [
    "### Uniformly from the interval [low, high) tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9390397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 5, 2],\n",
       "        [4, 3, 5, 2],\n",
       "        [4, 5, 4, 2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(low=2,high=6,size=tensor_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21a9034f",
   "metadata": {},
   "source": [
    "### Standard distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ca00fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3211,  0.1759, -1.4510,  1.5198],\n",
       "        [ 0.4456, -0.2399,  0.4471,  1.3005],\n",
       "        [-2.0173,  0.6138, -1.2153, -0.4869]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(tensor_shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03d30518",
   "metadata": {},
   "source": [
    "### Normal distribution with mean: `mean` and standard deviation: `std`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f0c33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1673, -0.9030,  1.0035,  0.2745],\n",
       "        [-0.2442,  1.4429, -1.0551, -0.3055],\n",
       "        [ 4.4262, -1.8558,  2.8828, -2.8617]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=0,std=2,size=tensor_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f200b0",
   "metadata": {},
   "source": [
    "## Same size tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "584c3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.randn(size=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75c9156f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20858c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "141dd251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 3.],\n",
       "        [2., 3., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint_like(tensor1,1,5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e6319c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Concatination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f4f0896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 9, 5],\n",
      "        [3, 3, 7, 7],\n",
      "        [4, 2, 9, 9],\n",
      "        [0, 3, 8, 5],\n",
      "        [1, 4, 7, 6],\n",
      "        [4, 3, 5, 9]]) \n",
      "\n",
      "\n",
      "torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.randint(0,5,(6,2))\n",
    "tensor2 = torch.randint(5,10,(6,2))\n",
    "new_tensor = torch.cat([tensor1,tensor2],dim=1)\n",
    "print(new_tensor,\"\\n\\n\")\n",
    "print(new_tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b16b3966",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7edb267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [9, 5]],\n",
      "\n",
      "        [[3, 3],\n",
      "         [7, 7]],\n",
      "\n",
      "        [[4, 2],\n",
      "         [9, 9]],\n",
      "\n",
      "        [[0, 3],\n",
      "         [8, 5]],\n",
      "\n",
      "        [[1, 4],\n",
      "         [7, 6]],\n",
      "\n",
      "        [[4, 3],\n",
      "         [5, 9]]]) \n",
      "\n",
      "\n",
      "torch.Size([6, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "new_tensor = torch.stack([tensor1,tensor2],dim=1)\n",
    "print(new_tensor,\"\\n\\n\")\n",
    "print(new_tensor.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2162a8a2",
   "metadata": {},
   "source": [
    "## Multiplication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43b6d3a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Elementwise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38e9d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.randint(0,5,(6,2))\n",
    "tensor2 = torch.randint(5,10,(6,2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3ec43bf",
   "metadata": {},
   "source": [
    "#### Method1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffdcba2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  5],\n",
       "        [27, 21],\n",
       "        [18,  0],\n",
       "        [14, 16]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.mul(tensor2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0f51761",
   "metadata": {},
   "source": [
    "#### Method2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6895fe5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  5],\n",
       "        [27, 21],\n",
       "        [18,  0],\n",
       "        [14, 16]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1*tensor2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf06c11c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "debcf5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.randint(0,5,(2,6))\n",
    "tensor2 = torch.randint(5,10,(6,2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d89add5",
   "metadata": {},
   "source": [
    "#### Method1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6efb799e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 99, 118],\n",
       "        [ 87,  91]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.matmul(tensor2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c34cd3d8",
   "metadata": {},
   "source": [
    "#### Method2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0de1a2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 99, 118],\n",
       "        [ 87,  91]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1@tensor2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d77f614c",
   "metadata": {},
   "source": [
    "## Rearrange dimensions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de61c8e6",
   "metadata": {},
   "source": [
    "### `.view()` vs `.reshape()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9059017",
   "metadata": {},
   "source": [
    "Here's a table that summarizes the differences between view and reshape in PyTorch:\n",
    "|          | `view`                              | `reshape`                         |\n",
    "|----------|-------------------------------------|----------------------------------|\n",
    "| New Data | No, shares data with original tensor | Yes, may create a copy of data    |\n",
    "| Speed    | Fast                                | Slower than `view`                |\n",
    "\n",
    "\n",
    "In general, if you want to modify the shape of a tensor without copying its underlying data, you should use view(). However, if you want to create a new tensor with a different shape, you should use reshape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0343a6b",
   "metadata": {},
   "source": [
    "#### `.reshape()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9043c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 3]) \n",
      "\n",
      "\n",
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(tensor)\n",
    "print(tensor.shape,\"\\n\\n\")\n",
    "\n",
    "new_tensor = tensor.reshape([6])\n",
    "print(new_tensor)\n",
    "print(new_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce154ea2",
   "metadata": {},
   "source": [
    "#### `.view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "895890e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 3]) \n",
      "\n",
      "\n",
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(tensor)\n",
    "print(tensor.shape,\"\\n\\n\")\n",
    "\n",
    "new_tensor = tensor.view([-1])\n",
    "print(new_tensor)\n",
    "print(new_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5796ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tensor[5] = torch.tensor(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4bd2bdcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 4,  5, 10]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d2469aa",
   "metadata": {},
   "source": [
    "### `.transpose()` vs `.permute()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1c13780",
   "metadata": {},
   "source": [
    "#### `.transpose()`\n",
    "* The transpose() function is used to switch the dimensions of a tensor. It takes a tensor as input and returns a new tensor with the dimensions transposed. For example, if the original tensor has shape (a, b, c), the transposed tensor will have shape (c, b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f0c6c72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 3])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of shape (3, 4, 5)\n",
    "x = torch.randn(3, 4, 5)\n",
    "\n",
    "# transpose the tensor to shape (5, 4, 3)\n",
    "y = x.transpose(0, 2).transpose(0,1)\n",
    "y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32c5d40c",
   "metadata": {},
   "source": [
    "#### `.permute()`\n",
    "* The permute() function is similar to transpose(), but it allows you to specify the order of the dimensions in the output tensor. It takes a tensor and a list of dimension indices as input and returns a new tensor with the dimensions permuted according to the indices. For example, if the original tensor has shape (a, b, c), and you want the output tensor to have shape (b, c, a), you can call tensor.permute(1, 2, 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eeb22df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a tensor of shape (3, 4, 5)\n",
    "x = torch.randn(3, 4, 5)\n",
    "\n",
    "# permute the tensor to shape (4, 5, 3)\n",
    "z = x.permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "36ee4070",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1a2b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d1a7eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy().transpose((1,2,0)).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7730f578",
   "metadata": {},
   "source": [
    "### `.squeeze()` and `.unsqueeze()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa774e36",
   "metadata": {},
   "source": [
    "* squeeze() and unsqueeze() are PyTorch tensor manipulation functions that are used to add or remove dimensions from a tensor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff233cc9",
   "metadata": {},
   "source": [
    "#### `.squeeze()`\n",
    "* The squeeze() function is used to remove dimensions of size 1 from a tensor. It takes a tensor as input and returns a new tensor with all dimensions of size 1 removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "976304ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor of shape (1,1,3)\n",
    "x = torch.tensor([[[1, 2, 3]]])\n",
    "\n",
    "# squeeze the tensor to remove the first dimension\n",
    "y = torch.squeeze(x)\n",
    "\n",
    "# print the shape of the original and squeezed tensors\n",
    "print(x.shape)  # torch.Size([1,1, 3])\n",
    "print(y.shape)  # torch.Size([1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "671861e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4372f27",
   "metadata": {},
   "source": [
    "#### `.unsqueeze()`\n",
    "* The unsqueeze() function is used to add a new dimension to a tensor at a specified position. It takes a tensor and a dimension index as input and returns a new tensor with the specified dimension added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "961e78ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# create a tensor of shape (3,)\n",
    "x = torch.tensor([1, 2, 3])\n",
    "\n",
    "# unsqueeze the tensor to add a new dimension at position 0\n",
    "y = torch.unsqueeze(x, 0)\n",
    "\n",
    "# print the shape of the original and unsqueezed tensors\n",
    "print(x.shape)  # torch.Size([3])\n",
    "print(y.shape)  # torch.Size([1, 3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97724757",
   "metadata": {},
   "source": [
    "### `.flatten()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b28850ba",
   "metadata": {},
   "source": [
    "* The flatten() function is used to convert a tensor with multiple dimensions into a 1-dimensional tensor. It takes a tensor as input and returns a new tensor with all dimensions flattened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2bebe316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4522,  1.1899,  1.7642, -0.6383, -0.5671,  1.0328,  0.4886, -1.6616,\n",
       "        -0.8207,  0.2764, -1.0302, -0.1928, -0.6488,  1.1651, -0.2780, -2.2664,\n",
       "        -1.1547, -0.4329,  0.4301, -0.6520, -0.2780, -1.8682,  0.1130,  1.6779,\n",
       "        -0.4416, -0.7924, -1.0833,  1.2409,  1.3294, -0.9036,  0.6870,  1.0764,\n",
       "        -1.8651, -0.2699,  1.0972,  0.5477, -0.4268,  0.8046, -1.2168,  0.3706,\n",
       "        -2.8509,  1.6846, -0.2054, -0.2326, -0.8687,  0.3140,  0.2960,  2.3124,\n",
       "        -1.0229,  0.4334, -1.1410,  1.4132, -1.4308, -0.6203,  0.5739,  0.7220,\n",
       "         1.0646, -0.0639,  0.3601, -0.6900])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of shape (3, 4, 5)\n",
    "x = torch.randn(3, 4, 5)\n",
    "\n",
    "# flatten the tensor to shape (60,)\n",
    "v = x.flatten()\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94f01d",
   "metadata": {},
   "source": [
    "## Contigous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734ba232",
   "metadata": {},
   "source": [
    "`.is_contiguous()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd14cb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init tensor: \n",
      " tensor([[ 6, 14, 17],\n",
      "        [ 3,  7,  2]]) \n",
      " Contigous:  True \n",
      "\n",
      "\n",
      "Here is the transposed tensor: \n",
      " tensor([[ 6,  3],\n",
      "        [14,  7],\n",
      "        [17,  2]]) \n",
      " Contigous:  False \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randint(20,[2,3])\n",
    "print(\"Init tensor: \\n\",tensor,\"\\n\", \"Contigous: \", tensor.is_contiguous(),\"\\n\\n\")\n",
    "\n",
    "transposed_tensor = tensor.transpose(1,0)\n",
    "print(\"Here is the transposed tensor: \\n\",transposed_tensor,\"\\n\", \"Contigous: \", transposed_tensor.is_contiguous(),\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4576536",
   "metadata": {},
   "source": [
    "`.contiguous()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8512d90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_tensor = transposed_tensor.contiguous()\n",
    "cont_tensor.is_contiguous()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8e25993",
   "metadata": {},
   "source": [
    "## Some methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca710422",
   "metadata": {},
   "source": [
    "#### `.numel()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b085ebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of this tensor is: torch.Size([3, 4, 10])\n",
      "outout of numer method is: 120\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randint(1,10,[3,4,10])\n",
    "print(f\"shape of this tensor is: {tensor.shape}\")\n",
    "print(f\"outout of numer method is: {torch.numel(tensor)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a700f22d",
   "metadata": {},
   "source": [
    "#### `.to()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7728e72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 7., 1., 2.],\n",
       "        [5., 8., 7., 9.],\n",
       "        [9., 9., 2., 8.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randint(1,10,[3,4])\n",
    "tensor = tensor.to(torch.float64)\n",
    "tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9dea8ac6c336defc73203621829f420c5c8cb20f705d9a92119e91f16d7af95c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
